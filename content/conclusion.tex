\chapter{Conclusion}

The goal of this work was to develop a hybrid approach that would be able to deal with common challenges in the automated semantic segmentation of medical images. These were, namely, a low volume of fully annotated data and a large volume of data that is only weakly annotated. The task was to segment the lymphocyte nuclei. This was also a great challenge, since many state-of-the-art works work with weak annotations in the form of bounding boxes, but their goal is to perform the nuclei segmentation, no matter the cell nuclei class, while in our work, we try to segment a specific class of nuclei - the lymphocyte nuclei. To our best knowledge at the time of writing, there is little to no available research papers on the exact specific setting we have. Two publicly available datasets were used for this task: the TIGER dataset \cite{tiger_dataset} with bounding box annotations of lymphocyte nuclei, and the TNBC \cite{TNBC-nuclei-seg-extended} dataset, which provided full pixel-level mask annotations of lymphocyte nuclei. 

We selected the deep learning model based on the state-of-the-art work and employed known methods of traditional computer vision, such as Otsu and adaptive thresholding, and mark-controlled watershed, to prepare different sets of pseudo-masks out of bounding box annotations. We then built further on the idea that each set could perform better on different images, so we developed different pseudo-mask fusion strategies.

In the experiments, we proved that training the model only on a very small TNBC dataset, although fully annotated, is insufficient. The same model, when trained on the larger TIGER dataset, even though with pseudo-masks used during the training, achieved superior results compared to the model trained solely on the TNBC dataset, both in terms of Dice coefficient and IoU. The model that used the best fused pseudo-mask showed improvements on both evaluation metrics as well. The final model that was pretrained on the TIGER dataset with pseudo-masks and then fine-tuned on the TNBC dataset was able to achieve the best results in Dice coefficient and IoU.

Possible future improvements may include a fully automated pipeline with an iterative self-training loop, where in the first iteration we train the model using pseudo-masks generated via the traditional computer vision pipeline, then let it predict the masks on the same dataset it was trained on, effectively creating a second generation of pseudo-labels. Then it would be retrained using the first generation of predictions, and so on, with iterative improvements of the pseudo-masks.


